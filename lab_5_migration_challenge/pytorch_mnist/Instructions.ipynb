{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCE SOLUTION: PyTorch MNIST Lift and Shift Exercise\n",
    "\n",
    "For this exercise notebook, use the `Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)` kernel on SageMaker Studio, or `conda_pytorch_p38` on classic SageMaker Notebook Instances.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Your new colleague in the data science team (who isn't very familiar with SageMaker) has written a nice notebook to tackle an image classification problem with PyTorch: [Local Notebook.ipynb](Local%20Notebook.ipynb).\n",
    "\n",
    "It works OK with the simple MNIST data set they were working on before, but now they'd like to take advantage of some of the features of SageMaker to tackle bigger and harder challenges.\n",
    "\n",
    "**Can you help refactor the Local Notebook code, to show them how to use SageMaker effectively?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "First, check you can **run the [Local Notebook.ipynb](Local%20Notebook.ipynb) notebook through** - reviewing what steps it takes.\n",
    "\n",
    "**This notebook** sets out a structure you can use to migrate code into, and lists out some of the changes you'll need to make at a high level. You can either work directly in here, or duplicate this notebook so you still have an unchanged copy of the original.\n",
    "\n",
    "Try to work through the sections first with an MVP goal in mind (fitting the model to data in S3 via a SageMaker Training Job, and deploying/using the model through a SageMaker Endpoint). At the end, there are extension exercises to bring in more advanced functionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Listing all our imports at the start helps to keep the requirements to run any script/file transparent up-front, and is specified by nearly every style guide including Python's official [PEP 8](https://www.python.org/dev/peps/pep-0008/#imports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipycanvas<0.13\n",
      "  Using cached ipycanvas-0.12.1-py2.py3-none-any.whl (257 kB)\n",
      "Collecting ipywidgets<8\n",
      "  Using cached ipywidgets-7.8.1-py2.py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.6.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from ipycanvas<0.13) (1.23.5)\n",
      "Requirement already satisfied: pillow>=6.0 in /opt/conda/lib/python3.9/site-packages (from ipycanvas<0.13) (9.4.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (0.2.0)\n",
      "Collecting widgetsnbextension~=3.6.6\n",
      "  Using cached widgetsnbextension-3.6.6-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting jupyterlab-widgets<3,>=1.0.0\n",
      "  Using cached jupyterlab_widgets-1.1.7-py3-none-any.whl (295 kB)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (8.10.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (5.9.0)\n",
      "Collecting comm>=0.1.3\n",
      "  Using cached comm-0.2.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (2.14.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (3.0.36)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.18.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.6.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (5.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting notebook>=4.4.1\n",
      "  Using cached notebook-7.0.6-py3-none-any.whl (4.0 MB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8) (0.8.3)\n",
      "Collecting notebook-shim<0.3,>=0.2\n",
      "  Using cached notebook_shim-0.2.3-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (6.2)\n",
      "Collecting jupyterlab<5,>=4.0.2\n",
      "  Using cached jupyterlab-4.0.9-py3-none-any.whl (9.2 MB)\n",
      "Collecting jupyter-server<3,>=2.4.0\n",
      "  Using cached jupyter_server-2.11.0-py3-none-any.whl (379 kB)\n",
      "Collecting jupyterlab-server<3,>=2.22.1\n",
      "  Using cached jupyterlab_server-2.25.2-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=4.0.0->ipywidgets<8) (0.2.10)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (3.1.2)\n",
      "Collecting jupyter-events>=0.9.0\n",
      "  Using cached jupyter_events-0.9.0-py3-none-any.whl (18 kB)\n",
      "Collecting overrides\n",
      "  Using cached overrides-7.4.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (24.0.1)\n",
      "Collecting anyio>=3.1.0\n",
      "  Using cached anyio-4.0.0-py3-none-any.whl (83 kB)\n",
      "Collecting nbconvert>=6.4.4\n",
      "  Using cached nbconvert-7.11.0-py3-none-any.whl (256 kB)\n",
      "Collecting jupyter-server-terminals\n",
      "  Using cached jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
      "Collecting send2trash>=1.8.2\n",
      "  Using cached Send2Trash-1.8.2-py3-none-any.whl (18 kB)\n",
      "Collecting websocket-client\n",
      "  Using cached websocket_client-1.6.4-py3-none-any.whl (57 kB)\n",
      "Collecting nbformat>=5.3.0\n",
      "  Using cached nbformat-5.9.2-py3-none-any.whl (77 kB)\n",
      "Collecting jupyter-client>=7.4.4\n",
      "  Using cached jupyter_client-8.6.0-py3-none-any.whl (105 kB)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.19.0-py3-none-any.whl (54 kB)\n",
      "Collecting jupyter-core!=5.0.*,>=4.12\n",
      "  Using cached jupyter_core-5.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Using cached terminado-0.18.0-py3-none-any.whl (14 kB)\n",
      "Collecting argon2-cffi\n",
      "  Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (5.5.6)\n",
      "Collecting tomli\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting async-lru>=1.0.0\n",
      "  Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /opt/conda/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (4.13.0)\n",
      "Collecting jupyter-lsp>=2.0.0\n",
      "  Using cached jupyter_lsp-2.2.0-py3-none-any.whl (65 kB)\n",
      "Collecting babel>=2.10\n",
      "  Using cached Babel-2.13.1-py3-none-any.whl (10.1 MB)\n",
      "Collecting jsonschema>=4.18.0\n",
      "  Using cached jsonschema-4.20.0-py3-none-any.whl (84 kB)\n",
      "Collecting json5>=0.9.0\n",
      "  Using cached json5-0.9.14-py2.py3-none-any.whl (19 kB)\n",
      "Collecting requests>=2.31\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (3.4)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.9/site-packages (from async-lru>=1.0.0->jupyterlab<5,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyterlab<5,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (3.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.1.2)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2023.11.1-py3-none-any.whl (17 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.31.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (22.2.0)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Using cached rpds_py-0.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting platformdirs>=2.5\n",
      "  Using cached platformdirs-4.0.0-py3-none-any.whl (17 kB)\n",
      "Collecting rfc3986-validator>=0.1.1\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (5.4.1)\n",
      "Collecting python-json-logger>=2.0.4\n",
      "  Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Collecting rfc3339-validator\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting bleach!=5.0.0\n",
      "  Using cached bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "Collecting mistune<4,>=2.0.3\n",
      "  Using cached mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting nbclient>=0.5.0\n",
      "  Using cached nbclient-0.9.0-py3-none-any.whl (24 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting tinycss2\n",
      "  Using cached tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting fastjsonschema\n",
      "  Using cached fastjsonschema-2.19.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.1.1)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting webcolors>=1.11\n",
      "  Using cached webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Collecting uri-template\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Collecting jsonpointer>1.13\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting isoduration\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Collecting fqdn\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (1.15.1)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8) (2.21)\n",
      "Collecting arrow>=0.15.0\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Collecting types-python-dateutil>=2.8.10\n",
      "  Using cached types_python_dateutil-2.8.19.14-py3-none-any.whl (9.4 kB)\n",
      "Installing collected packages: webencodings, types-python-dateutil, json5, fastjsonschema, websocket-client, webcolors, uri-template, tomli, tinycss2, terminado, soupsieve, sniffio, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, requests, python-json-logger, prometheus-client, platformdirs, pandocfilters, overrides, mistune, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, fqdn, exceptiongroup, defusedxml, comm, bleach, babel, async-lru, referencing, jupyter-server-terminals, jupyter-core, beautifulsoup4, arrow, argon2-cffi-bindings, anyio, jupyter-client, jsonschema-specifications, isoduration, argon2-cffi, jsonschema, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, widgetsnbextension, ipywidgets, ipycanvas\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.2\n",
      "    Uninstalling requests-2.28.2:\n",
      "      Successfully uninstalled requests-2.28.2\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.9.2\n",
      "    Uninstalling jupyter-core-4.9.2:\n",
      "      Successfully uninstalled jupyter-core-4.9.2\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 6.1.5\n",
      "    Uninstalling jupyter-client-6.1.5:\n",
      "      Successfully uninstalled jupyter-client-6.1.5\n",
      "Successfully installed anyio-4.0.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.4 babel-2.13.1 beautifulsoup4-4.12.2 bleach-6.1.0 comm-0.2.0 defusedxml-0.7.1 exceptiongroup-1.2.0 fastjsonschema-2.19.0 fqdn-1.5.1 ipycanvas-0.12.1 ipywidgets-7.8.1 isoduration-20.11.0 json5-0.9.14 jsonpointer-2.4 jsonschema-4.20.0 jsonschema-specifications-2023.11.1 jupyter-client-8.6.0 jupyter-core-5.5.0 jupyter-events-0.9.0 jupyter-lsp-2.2.0 jupyter-server-2.11.0 jupyter-server-terminals-0.4.4 jupyterlab-4.0.9 jupyterlab-pygments-0.2.2 jupyterlab-server-2.25.2 jupyterlab-widgets-1.1.7 mistune-3.0.2 nbclient-0.9.0 nbconvert-7.11.0 nbformat-5.9.2 notebook-7.0.6 notebook-shim-0.2.3 overrides-7.4.0 pandocfilters-1.5.0 platformdirs-4.0.0 prometheus-client-0.19.0 python-json-logger-2.0.7 referencing-0.31.0 requests-2.31.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.13.1 send2trash-1.8.2 sniffio-1.3.0 soupsieve-2.5 terminado-0.18.0 tinycss2-1.2.1 tomli-2.0.1 types-python-dateutil-2.8.19.14 uri-template-1.3.0 webcolors-1.13 webencodings-0.5.1 websocket-client-1.6.4 widgetsnbextension-3.6.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"ipycanvas<0.13\" \"ipywidgets<8\" matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Local Notebook Utils:\n",
    "import util\n",
    "\n",
    "# TODO: What else will you need?\n",
    "# Have a look at the documentation: https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html\n",
    "# to see which libraries need to be imported to use sagemaker and the PyTorch estimator\n",
    "from PIL import Image\n",
    "import sagemaker\n",
    "from IPython.display import HTML, display\n",
    "from sagemaker.pytorch import PyTorch as PyTorchEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "Let's download the image data from the Repository of Open Data on AWS and sample a subset like we did in the [Local Notebook.ipynb](Local%20Notebook.ipynb).\n",
    "\n",
    "**Check you understand** what data it's going to upload from this notebook, and where it's going to store it in S3, then start the upload running while you work on the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-imageclas/mnist_png.tgz to ../../../../tmp/mnist/mnist_png.tgz\n",
      "Training files: 60000\n",
      "Testing files:  10000\n",
      "Training files kept: 30000\n",
      "Testing files kept:  5000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "local_dir = \"/tmp/mnist\"\n",
    "training_dir = f\"{local_dir}/training\"\n",
    "testing_dir = f\"{local_dir}/testing\"\n",
    "\n",
    "# Download the MNIST data from the Registry of Open Data on AWS\n",
    "!rm -rf {local_dir}\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-imageclas/mnist_png.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the MNIST data, stripping the leading path element; this will leave us with directories\n",
    "# {local_dir}/testing/ and {local_dir/training/\n",
    "!tar zxf {local_dir}/mnist_png.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "\n",
    "# Get the list of files in tne training and testing directories recursively\n",
    "train_files = sorted(list(glob.iglob(os.path.join(training_dir, \"*/*.png\"), recursive=True)))\n",
    "test_files = sorted(list(glob.iglob(os.path.join(testing_dir, \"*/*.png\"), recursive=True)))\n",
    "\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Testing files:  {len(test_files)}\")\n",
    "\n",
    "# Reduce the data by keeping every Nth file and dropping the rest of the files.\n",
    "reduction_factor = 2\n",
    "train_files_to_keep = train_files[::reduction_factor]\n",
    "test_files_to_keep = test_files[::reduction_factor]\n",
    "\n",
    "print(f\"Training files kept: {len(train_files_to_keep)}\")\n",
    "print(f\"Testing files kept:  {len(test_files_to_keep)}\")\n",
    "\n",
    "# Delete all the files not to be kept\n",
    "for fname in set(train_files) ^ set(train_files_to_keep):\n",
    "    os.remove(fname)\n",
    "\n",
    "for fname in set(test_files) ^ set(test_files_to_keep):\n",
    "    os.remove(fname)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Execution Role, Session and S3 Bucket\n",
    "\n",
    "Now that we have downloaded and reduced the data in the local directory, we will need to upload it to Amazon S3 to make it available for Amazon Sagemaker training.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting. If you don't specify a bucket, SageMaker SDK will create a default bucket following a pre-defined naming convention in the same region.\n",
    "- The IAM role ARN used to give SageMaker access to your data. It can be fetched using the **get_execution_role** method from SageMaker Python SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: This is where you can setup execution role, session and S3 bucket.\n",
    "# 1. Setup the SageMaker role\n",
    "role = sagemaker.get_execution_role()\n",
    "# 2. Setup the SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "# 3. Setup the SageMaker default bucket\n",
    "bucket_name = sess.default_bucket()  # We'll just use the default bucket as the other examples did\n",
    "\n",
    "# Have a look at the previous examples to find out how to do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to Amazon S3\n",
    "Next is the part where you need to upload the images to Amazon S3 for Sagemaker training. You can refer to the previous example on how to do it using the [aws s3 sync](https://docs.aws.amazon.com/cli/latest/reference/s3/sync.html) CLI command. The high-level command `aws s3 sync` command synchronizes the contents of the target bucket and source directory. It allows the use of options such as `--delete` that allows to remove objects from the target that are not present in the source and `--exclude` or `--include` options that filter files or objects to exclude or not exclude.\n",
    "\n",
    "> ⏰ Note: Uploading to Amazon S3 typically takes about 2-3 minutes assuming a `reduction_factor` of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# TODO: This is where you upload the training images using `aws s3 sync`.\n",
    "# Fill in the missing source local directory and the target S3 bucket and folder in the command below.\n",
    "!aws s3 sync --quiet --delete {local_dir} s3://{bucket_name}/mnist --exclude \"*.tgz\" && echo \"Done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your data is uploaded by finding your bucket in the [Amazon S3 Console](https://s3.console.aws.amazon.com/s3/home). Do you see the folders of images as expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input (\"Channels\") Configuration\n",
    "\n",
    "The draft code has **2 data sets**: One for training, and one for test/validation. (For classification, the folder location of each image is sufficient as a label).\n",
    "\n",
    "In SageMaker terminology, each input data set is a \"channel\" and we can name them however we like... Just make sure you're consistent about what you call each one!\n",
    "\n",
    "For a simple input configuration, a channel spec might just be the S3 URI of the folder. For configuring more advanced options, there's the [s3_input](https://sagemaker.readthedocs.io/en/stable/inputs.html) class in the SageMaker SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <sagemaker.inputs.TrainingInput object at 0x7faf94cc0f70>, 'test': 's3://sagemaker-us-east-1-213450005126/mnist/testing'}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Define your 2 data channels\n",
    "# The data can be found in: \"s3://{bucket_name}/mnist/train\" and \"s3://{bucket_name}/mnist/test\"\n",
    "\n",
    "# We can use either the s3_input (which gives us additional configuration options), or a plain string:\n",
    "train_channel = sagemaker.inputs.TrainingInput(f\"s3://{bucket_name}/mnist/training\")\n",
    "test_channel = f\"s3://{bucket_name}/mnist/testing\"\n",
    "\n",
    "inputs = {\"train\": train_channel, \"test\": test_channel}\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm (\"Estimator\") Configuration and Run\n",
    "\n",
    "Instead of loading and fitting this data here in the notebook, we'll be creating a [PyTorch Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html#pytorch-estimator) through the SageMaker SDK, to run the code on a separate container that can be scaled as required.\n",
    "\n",
    "The [\"Using PyTorch with the SageMaker Python SDK\"](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html) docs give a good overview of this process. You should run your estimator in **Python 3**.\n",
    "\n",
    "**Use the [src/main.py](src/main.py) file** as your entry point to port code into - which has already been created for you with some basic hints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Create your PyTorch estimator\n",
    "\n",
    "# Note the PyTorch class inherits from some cross-framework base classes with additional\n",
    "# constructor options:\n",
    "# https://sagemaker.readthedocs.io/en/stable/estimators.html\n",
    "# https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#create-an-estimator\n",
    "\n",
    "# We are using PyTorch 1.8 and python 3\n",
    "# You can reuse the metrics definition from the previous example\n",
    "# (Optional) Look at the Pytorch script and try to pass new hyperparameters\n",
    "\n",
    "estimator = PyTorchEstimator(\n",
    "    role=role,  # IAM role to run the job under - we just use the same as the notebook role\n",
    "    ## Framework setup:\n",
    "    entry_point=\"main.py\",  # Target script\n",
    "    source_dir=\"./src\",  # Folder to bundle, in case we want to split the code between files\n",
    "    framework_version=\"1.10\",  # PyTorch version\n",
    "    py_version=\"py38\",  # Python version\n",
    "    ## Infrastructure provisioning:\n",
    "    instance_count=1,  # We haven't implemented parallelization in our script\n",
    "    # instance_type=\"ml.p3.2xlarge\",  # Keras should be accelerated by GPU though\n",
    "    instance_type=\"ml.c5.2xlarge\",  # Keras should be accelerated by GPU though\n",
    "    max_run=30 * 60,  # The training shouldn't take too long to run\n",
    "    use_spot_instances=True,  # May as well use spot to save money\n",
    "    max_wait=40 * 60,  # ...And we don't want to wait for ages for spot instances\n",
    "    ## Parameters to pass to our script:\n",
    "    hyperparameters={\n",
    "        \"epochs\": 12,\n",
    "        \"batch-size\": 128,\n",
    "    },\n",
    "    ## Performance/progress metrics to scrape from console output:\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"epoch\", \"Regex\": \"epoch: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"train:loss\", \"Regex\": \"train_loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"test:loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"test:accuracy\", \"Regex\": \"val_acc: ([0-9\\\\.]+)\"},\n",
    "    ],\n",
    "    ## Let's keep our SageMaker records tidy by giving the training jobs a sensible name\n",
    "    base_job_name=\"mnist-pytorch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the actual training on SageMaker TrainingJob, it can be good to run it locally first using the code below. If there is any error, you can fix them first before running using SageMaker TrainingJob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading label 0...1...2...3...4...5...6...7...8...9...Shuffling trainset...\n",
      "Shuffling testset...\n",
      "x_train shape: (30000, 1, 28, 28)\n",
      "input_shape: (1, 28, 28)\n",
      "30000 train samples\n",
      "5000 test samples\n",
      "n_labels: 10\n",
      "y_train shape: (30000, 10)\n",
      "model init\n",
      "[2023-11-21 16:10:12.939 pytorch-1-13-cpu-py39-ml-t3-medium-9140905751f3e451a2295c86a7c3:226 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-11-21 16:10:13.554 pytorch-1-13-cpu-py39-ml-t3-medium-9140905751f3e451a2295c86a7c3:226 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "epoch: 1\n",
      "train_loss: 0.000819\n",
      "Evaluating model\n",
      "val_loss: 0.0396\n",
      "val_acc: 0.9258\n",
      "epoch: 2\n",
      "train_loss: 0.000327\n",
      "Evaluating model\n",
      "val_loss: 0.0202\n",
      "val_acc: 0.9664\n"
     ]
    }
   ],
   "source": [
    "!python3 src/main.py --train {training_dir} --test {testing_dir} --output-data-dir data/local-output --model-dir data/local-model --epochs=2 --batch-size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're ready to try your script in a Sagemaker training job, you can call `estimator.fit()` as we did in previous exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: mnist-pytorch-2023-11-21-16-12-26-006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-21 16:12:26 Starting - Starting the training job...\n",
      "2023-11-21 16:12:43 Starting - Preparing the instances for training.........\n",
      "2023-11-21 16:14:17 Downloading - Downloading input data......\n",
      "2023-11-21 16:15:13 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:20,192 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:20,193 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:20,200 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:20,202 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:20,398 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:21,432 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:21,432 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:21,435 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:21,445 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:21,455 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-11-21 16:15:21,462 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"epochs\": 12\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"mnist-pytorch-2023-11-21-16-12-26-006\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-213450005126/mnist-pytorch-2023-11-21-16-12-26-006/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":128,\"epochs\":12}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-213450005126/mnist-pytorch-2023-11-21-16-12-26-006/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.c5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":12},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"mnist-pytorch-2023-11-21-16-12-26-006\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-213450005126/mnist-pytorch-2023-11-21-16-12-26-006/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"12\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=12\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20220929-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 main.py --batch-size 128 --epochs 12\u001b[0m\n",
      "\u001b[34mLoading label 0...\u001b[0m\n",
      "\u001b[34m1...\u001b[0m\n",
      "\u001b[34m2...\u001b[0m\n",
      "\u001b[34m3...\u001b[0m\n",
      "\u001b[34m4...\u001b[0m\n",
      "\u001b[34m5...\u001b[0m\n",
      "\u001b[34m6...\u001b[0m\n",
      "\u001b[34m7...\u001b[0m\n",
      "\u001b[34m8...\u001b[0m\n",
      "\u001b[34m9...\u001b[0m\n",
      "\u001b[34mShuffling trainset...\u001b[0m\n",
      "\u001b[34mShuffling testset...\u001b[0m\n",
      "\u001b[34mx_train shape: (30000, 1, 28, 28)\u001b[0m\n",
      "\u001b[34minput_shape: (1, 28, 28)\u001b[0m\n",
      "\u001b[34m30000 train samples\u001b[0m\n",
      "\u001b[34m5000 test samples\u001b[0m\n",
      "\u001b[34mn_labels: 10\u001b[0m\n",
      "\u001b[34my_train shape: (30000, 10)\u001b[0m\n",
      "\u001b[34mmodel init\u001b[0m\n",
      "\u001b[34m[2023-11-21 16:15:25.816 algo-1:45 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-11-21 16:15:26.059 algo-1:45 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-11-21 16:15:26.060 algo-1:45 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-11-21 16:15:26.060 algo-1:45 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-11-21 16:15:26.061 algo-1:45 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-11-21 16:15:26.061 algo-1:45 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mepoch: 1\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000837\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0380\u001b[0m\n",
      "\u001b[34mval_acc: 0.9334\u001b[0m\n",
      "\u001b[34mepoch: 2\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000324\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0192\u001b[0m\n",
      "\u001b[34mval_acc: 0.9670\u001b[0m\n",
      "\u001b[34mepoch: 3\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000218\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0133\u001b[0m\n",
      "\u001b[34mval_acc: 0.9764\u001b[0m\n",
      "\u001b[34mepoch: 4\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000181\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0124\u001b[0m\n",
      "\u001b[34mval_acc: 0.9764\u001b[0m\n",
      "\u001b[34mepoch: 5\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000148\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0107\u001b[0m\n",
      "\u001b[34mval_acc: 0.9802\u001b[0m\n",
      "\u001b[34mepoch: 6\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000129\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0095\u001b[0m\n",
      "\u001b[34mval_acc: 0.9828\u001b[0m\n",
      "\u001b[34mepoch: 7\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000111\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0093\u001b[0m\n",
      "\u001b[34mval_acc: 0.9824\u001b[0m\n",
      "\u001b[34mepoch: 8\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000103\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0085\u001b[0m\n",
      "\u001b[34mval_acc: 0.9854\u001b[0m\n",
      "\u001b[34mepoch: 9\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000089\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0084\u001b[0m\n",
      "\u001b[34mval_acc: 0.9852\u001b[0m\n",
      "\u001b[34mepoch: 10\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000085\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0083\u001b[0m\n",
      "\u001b[34mval_acc: 0.9848\u001b[0m\n",
      "\u001b[34mepoch: 11\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000078\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0079\u001b[0m\n",
      "\u001b[34mval_acc: 0.9846\u001b[0m\n",
      "\u001b[34mepoch: 12\u001b[0m\n",
      "\u001b[34mtrain_loss: 0.000076\u001b[0m\n",
      "\u001b[34mEvaluating model\u001b[0m\n",
      "\u001b[34mval_loss: 0.0072\u001b[0m\n",
      "\u001b[34mval_acc: 0.9870\u001b[0m\n",
      "\u001b[34m2023-11-21 16:18:24,813 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-11-21 16:18:24,814 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-11-21 16:18:24,814 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-11-21 16:18:44 Uploading - Uploading generated training model\n",
      "2023-11-21 16:18:44 Completed - Training job completed\n",
      "Training seconds: 267\n",
      "Billable seconds: 125\n",
      "Managed Spot Training savings: 53.2%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Call estimator.fit\n",
    "estimator.fit(inputs)\n",
    "\n",
    "# Note: As configured, this job took about 12 clock minutes (but only 3 billable minutes) to run,\n",
    "# reaching a test accuracy of ~82%. The majority of the time is the download of images to the\n",
    "# container - which could be significantly optimized as discussed later in the \"Further\n",
    "# Improvements\" section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and Use Your Model (Real-Time Inference)\n",
    "\n",
    "If your training job has completed; and saved the model in the correct PyTorch model format; it should now be pretty simple to deploy the model to a real-time endpoint.\n",
    "\n",
    "You can achieve this with the [Estimator API](https://sagemaker.readthedocs.io/en/stable/estimators.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: mnist-pytorch-2023-11-21-16-19-15-048\n",
      "INFO:sagemaker:Creating endpoint-config with name mnist-pytorch-2023-11-21-16-19-15-048\n",
      "INFO:sagemaker:Creating endpoint with name mnist-pytorch-2023-11-21-16-19-15-048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "# TODO: Deploy a real-time endpoint\n",
    "predictor = estimator.deploy(\n",
    "    # Low request volume, tiny model = tiny infrastructure is fine:\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the architecture from the example notebook, we set up the model to accept **batches** of **28x28** image tensors with **normalized 0-1 pixel values** and a **single color channel dimension**.\n",
    "\n",
    "Assuming you haven't [added any custom inference pre-processing](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#serve-a-pytorch-model) to the script (for example to accept encoded JPEGs/PNGs, or arbitrary image shapes), we'll need to replicate that same format when we use our endpoint.\n",
    "\n",
    "You can use the final \"Explore Results\" section of the local notebook as a guide. First, using the interactive widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2b2e54a86a424e9fc5bc453be7cf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Draw a digit!</h3>'), Button(description='Clear', icon='eraser', style=ButtonSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create/reload the drawing widget:\n",
    "widget = util.draw.PixelDrawCanvas(pen_size=4)\n",
    "widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request data shape (1, 1, 28, 28), type float32\n",
      "Result confidences: [[0.09024136 0.1134364  0.09563513 0.10736959 0.09579602 0.10603072\n",
      "  0.09638395 0.10174284 0.09619851 0.09716555]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the image from the widget:\n",
    "img = widget.data.mean(-1) / 255  # (Convert full-RGB 0-255 to grayscale 0-1)\n",
    "\n",
    "# TODO: Call your endpoint\n",
    "input_data = np.expand_dims(img, [0, 1]).astype(np.float32)\n",
    "print(f\"Request data shape {input_data.shape}, type {input_data.dtype}\")\n",
    "result = predictor.predict(input_data)\n",
    "\n",
    "print(f\"Result confidences: {result}\")\n",
    "\n",
    "# Plot the result:\n",
    "plt.figure(figsize=(3, 3))\n",
    "fig = plt.subplot(1, 1, 1)\n",
    "ax = plt.imshow(img, cmap=\"gray\")\n",
    "fig.set_title(f\"Predicted Number {np.argmax(result)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, to load and classify images from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request data shape (1, 1, 28, 28), type float32\n",
      "Result confidences: [[3.61463428e-08 4.85638338e-06 1.15449257e-06 1.09435161e-09\n",
      "  9.99979615e-01 1.89576880e-07 7.06375900e-08 2.05969897e-07\n",
      "  1.30838807e-05 6.54293217e-07]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADSCAYAAAD66wTTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQaklEQVR4nO3de5SU9X3H8fcHvKCARE3wTrCReAnHYKKohyaSGitVc7xUE6n1GkXPkRo9qdF6LHJMvEVjY2uNBSWiIfF+K9ZEYxvF4xUpDVhDRF0VXUGCILZaRL/9Y541w29/w87uzM7uDJ/XOXtm5ju/eZ7fM7uffS7zzO9RRGBmfzSgrztg1t84FGYJh8Is4VCYJRwKs4RDYZZwKKog6SZJPyjuf0XSogbNNyTt0oh5dUXSVEk/6+t+NELLhEJSm6T3Jb0naamkn0oaUu/5RMSciNi1iv6cJOnxes+/bPq/kfSBpJ3Kal+X1NZb82wESZtI+p2kJX3Vh5YJReEbETEE+BKwD3Bh2kDSRg3vVe/5H+Dv+7oT3dXF7+BcYFmj+pLTaqEAICLeAB4ERsMnmyFnSnoReLGoHSZpvqSVkp6QtGfH6yXtJWmepNWSbgMGlT03vvy/mKSdJN0t6W1Jf5B0raTdgeuB/Ys118qi7aaSrpL0WrE2u17SZmXTOldSu6Q3JZ1SxaL+IzCx0iZWuvmVbAaOl7RE0vckLSvme4SkQyT9XtIKSRckkxwk6bbifZkn6Ytl095e0l3F+/CKpLPKnpsq6U5JP5P0LnBShf7uDPw1cFkVy95rWjIUxSbFIcB/lpWPAPYF9pD0JWAGcDqwNfAvwP3FH+0mwL3ALcBWwB3AX1aYz0BgNvAqMBLYAbg1Il4AzgCejIghEfGp4iVXAJ8HxgC7FO2nFNOaAPwtcBAwCvh6FYv6BjAdmFpF25xtKQW+ox/TKf1Rfhn4CjBF0p+UtT+c0vuxFfBz4F5JG0saAPwr8F/FtA4EzpZ0cPLaO4FPAbMq9OefgAuA93u4PPURES3xA7QB7wErKf2RXgdsVjwXwJ+Vtf0J8P3k9YuAA4CvAm8CKnvuCeAHxf3xwJLi/v7A28BGmf6cBDxe9liUNnc+V1bbH3iluD8DuLzsuc8X/d6lwvL+BjgV+AywCvgCpSC1lbVZ5/XATclyvA8MLB4PLdrvW9b+OeCI4v5U4Kmy5wYA7ZTCsy/wWtK/vwN+Wvbax7r4/R0J/DJ9j/vip5W2r6H0C/x1hedeL7v/WeBESX9TVtsE2J7SH8YbUfx2Cq9WmOZOwKsRsbaKvn0G2Bx4TlJHTcDA4v72lP4Iu5rnOiLibUnXAhdTCnt3/CEiPirud/x3Xlr2/PtA+cGKT97DiPi42IzseM+279hMLAwE5uRem5I0GPghpbV7n2u1UKxP+R/568AlEXFJ2kjSAcAOklQWjBHAS5lpvg6MkLRRJhjp6cfLKf2RfSFK+zypdkoh6zCi8qJ0ciXwMvBMUv9fSkHssC1Qy1Gd8iNdA4AdKa1V11Ja441az2vXdzr2KEqbn3OKfxibAMMkvQXsFxFtNfS521pyn6IK04EzJO2rksGSDpU0FHiS0i/5LEkbSToKGFthOs9Q+mO+vJjGIEnjiueWAjsW+yhExMfFfP9B0nAASTuUbXffDpwkaQ9JmwMXVbswEbES+BHwveSp+cBfSRpY7LMcUO00K/iypKOKo0dnA/8HPEXpfXhX0nmSNivmN1rSPlVOdyGlwI0pfk6l9P6NYT1rmN6yQYYiIuYCpwHXAu8AiymOiETEGuCo4vE7wLeAuytM5yPgG5R2ml+j9F/4W8XT/w48D7wlaXlRO6+Y11PFUZhfA7sW03oQ+HHxusXFbXdcA3yU1L5T9G8lcBylAwi1uI/S8r0DHA8cFREflr0PY4BXKK0VbwCGVTPRiFgbEW91/AArgI+Lx+ky9Tqtu+lsZhvkmsJsfRwKs4RDYZZwKMwSNYVC0gRJiyQtlnR+vTpl1pd6fPSpOO/n95TO1VkCPAtMjIj/Xs9rfKjL+o2IUK5ey5piLLA4Il4uju3fSumkL7OmVksodmDdTxuXFDWzplbLuU+5VU+nzSNJk4BJNczHrKFqCcUS1j2BrePksHVExDRgGnifwppDLZtPzwKjJO1cnPR2LHB/fbpl1nd6vKaIiLWSJgO/onTu/IyIeL5uPTPrIw09IdCbT9af9MYhWbOW5FCYJRwKs4RDYZZwKMwSDoVZwqEwSzgUZgmHwizhUJglHAqzhENhlnAozBIOhVnCoTBLOBRmCYfCLOFQmCUcCrOEQ2GWqOlCkJLagNWULiu1NiL2rkenrHlsscUW2fopp5ySrV999dXZ+sknn5ytz5w5s2cdq0E9ro76tYhY3nUzs+bgzSezRK2hCOAhSc8VY8aaNb1aN5/GRcSbxXWhH5b0u4h4rLyBB1i2ZlPTmiIi3ixulwH3kLkIe0RMi4i9vRNuzaLHawpJg4EBEbG6uP/nwMV165lVNGjQoGz92GOPzdZvueWWbP2jj2q/bvuIESOy9SlTpmTrlYZpXbRoUc19qZdaNp+2Ae6R1DGdn0fEL+vSK7M+VMuo4y8DX6xjX8z6BR+SNUs4FGYJh8IsUY/TPKzBbrzxxmx94sSJ2fry5fmzcGbPnl1zXypNY9iwYdn6HXfcka3Pmzev5r7Ui9cUZgmHwizhUJglHAqzhENhlvDRp35s+PDh2fquu+6arbe3t2frCxcurHmeF1+cP62t0rlPzz+fv6T6hRdemK2vWbOmit41htcUZgmHwizhUJglHAqzhENhlvDRp37s+uuvz9b32muvbP3UU0/N1tva2qqe52677Zatn3baaVVPA+Doo4/O1hcvXtyt6fQFrynMEg6FWcKhMEs4FGaJLkMhaYakZZIWltW2kvSwpBeL2y17t5tmjaNK4/B80kD6KvAecHNEjC5qPwRWRMTlks4HtoyI87qcmbT+mW2gJk3KD6BY6ejT0qVLs/XtttuuW/M9+OCDO9XuueeebNtVq1Zl65WOStXjW329LSKUq3e5piiGwVyRlA8HOsZInwkcUUvnzPqTnu5TbBMR7QDFbf7USrMm1Osf3nmAZWs2PV1TLJW0HUBxu6xSQw+wbM2mp2uK+4ETgcuL2/vq1qMWVmlH+Morr8zW165dm60ff/zx3Zrv5ptvnq2fddZZnWqbbrpptu2dd96ZrTfDDnV3VXNI9hfAk8CukpZI+jalMBwk6UXgoOKxWUvock0REfkRtuDAOvfFrF/wJ9pmCYfCLOFQmCX8JaNesvXWW3eqXXrppdm2Q4YMydaffvrpbH3BggXd6ssVV1yRrU+YMKFT7Yknnsi2veiii7o1z2bmNYVZwqEwSzgUZgmHwizhUJglfPSpl0yePLlT7YQTTsi2Xb16dbZe6TJelb5kdMwxx2Trp59+etXzvemmm7JtV6xIv1LTurymMEs4FGYJh8Is4VCYJRwKs4SPPtXosMMOy9Zz5wpVGk7opZdeyta32GKLbH3OnDnZ+rhx47L1SvN98MEHO9VmzZqVbbsh8ZrCLOFQmCUcCrOEQ2GW6OkAy1MlvSFpfvFzSO9206xxejrA8lTgvYi4qlsza+IBlkeOHJmt33dffsirPffcs1Otq/e6VlJ2vOBuzfeGG27I1isNAt3M6j3AslnLqmWfYrKk3xabV74+hbWMnobiJ8DngDFAO/CjSg0lTZI0V9LcHs7LrKF6FIqIWBoRH0XEx8B0YOx62nqAZWsqPQpFx4jjhSOBhZXamjWbLs99KgZYHg98WtIS4CJgvKQxQABtQP6rXU2o0qjb55xzTrY+evTobD13xKe3jz59+OGH2frUqVOz9SlTpnSqffDBB/XsUlPq6QDL+e9JmrUAf6JtlnAozBIOhVnCoTBLdHnuU11n1o/Ofap0lOnmm2/O1o8++uhuTT93HtIDDzyQbTt9+vRu9WXo0KHZ+q233pqtH3fccdn62LGdP16aP39+tu2aNWuy9WbW43OfzDY0DoVZwqEwSzgUZokNdoibRx99NFvfZ599ujWdlStXZuuHHnpop9qzzz6bbVtpYOTBgwd3a56XXXZZtl7JM8880632GwqvKcwSDoVZwqEwSzgUZgmHwiyxwR59mjFjRrZe6ejTddddl61fc8012frixYs71QYNGpRte+6552brAwbk/2dVulj8woX+AmQ9eE1hlnAozBIOhVnCoTBLOBRmiWoGWN4JuBnYFvgYmBYR10jaCrgNGElpmJtvRsQ7XUyr33zJqLftsssunWqVzn0aNmxYtv7YY49l6+PHj+9xv+yPavmS0VrguxGxO7AfcKakPYDzgUciYhTwSPHYrOlVM+p4e0TMK+6vBl4AdgAOB2YWzWYCR/RSH80aqlsf3kkaCewFPA1sExHtUAqOpOEVXjMJaL2LG1jLqjoUkoYAdwFnR8S7lS4QkoqIacC0YhobzD6FNa+qjj5J2phSIGZFxN1FeWnHQMvF7bLe6aJZY1UzwLIojR37QkRcXfbU/cCJwOXFbf46Vy2u0vlMuYvOV7pY/IIFC7L1iRNzw/hab6tm82kccDywQNL8onYBpTDcLunbwGtA/juVZk2mmlHHHwcq7UAcWN/umPU9f6JtlnAozBIOhVligx1guV66c+msVatWZdvuvvvu2fpbb73V435Z1zzAslmVHAqzhENhlnAozBIOhVligx33qbsqnYd0/vn571a1tbV1qp1xxhnZtj7K1L94TWGWcCjMEg6FWcKhMEs4FGYJH32qUqXrz2288cbZem4k8YceeqiufbLe4TWFWcKhMEs4FGYJh8IsUcsAy1OB04C3i6YXRMS/dTGtlvuSkTWvSl8yqiYU2wHbRcQ8SUOB5yiNG/tN4L2IuKraTjgU1p9UCkU1Q9y0Ax1jxq6W1DHAsllL6tY+RTLAMsBkSb+VNEPSlhVeM0nSXElza+uqWWNUPXBBMcDyo8AlEXG3pG2A5UAA36e0iXVKF9Pw5pP1Gz3ep4BPBlieDfwqGU+24/mRwOyIGN3FdBwK6zd6PJpHpQGWO0YcLxwJ+Mrm1hKqOfr0p8AcYAGlQ7JQGmB5IjCG0uZTG3B6x0Vc1jMtryms36hp86leHArrTzwYmlmVHAqzhENhlnAozBIOhVnCoTBLOBRmCYfCLOFQmCUaPcTNcuDV4v6ni8etzsvZP3220hMNPc1jnRlLcyNi7z6ZeQN5OZuPN5/MEg6FWaIvQzGtD+fdSF7OJtNn+xRm/ZU3n8wSDQ+FpAmSFklaLCl/wbgmVYxqskzSwrLaVpIelvRicZsd9aSZSNpJ0n9IekHS85K+U9RbYlkbGgpJA4F/Bv4C2AOYKGmPRvahl90ETEhq5wOPRMQo4JHicbNbC3w3InYH9gPOLH6PLbGsjV5TjAUWR8TLEbEGuBU4vMF96DUR8RiwIikfDsws7s+kNLpiU4uI9oiYV9xfDXQMkNcSy9roUOwAvF72eAmtP9rgNh0DOhS3w/u4P3WVDJDXEsva6FDkvijuw19Nqhgg7y7g7Ih4t6/7Uy+NDsUSYKeyxzsCbza4D422tGOMrOJ2WR/3py6KAfLuAmZFxN1FuSWWtdGheBYYJWlnSZsAxwL3N7gPjXY/cGJx/0Tgvj7sS11UGiCPFlnWhn94J+kQ4MfAQGBGRFzS0A70Ikm/AMZTOmN0KXARcC9wOzACeA04JiLSnfGmsp4B8p6mBZbVn2ibJfyJtlnCoTBLOBRmCYfCLOFQmCUcCrOEQ2GWcCjMEv8PRxxLoot7UFkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Choose an image\n",
    "label = \"4\"\n",
    "filename = os.listdir(f\"{testing_dir}/{label}\")[0]\n",
    "\n",
    "# TODO: Load the image.\n",
    "# Note: Can feed numpy array to predictor. There is no need to build tensor.\n",
    "# Load the image:\n",
    "img = Image.open(f\"{testing_dir}/{label}/{filename}\")\n",
    "input_data = np.squeeze(np.asarray(img)).astype(np.float32) / 255\n",
    "input_data = np.expand_dims(np.expand_dims(input_data, 0), 0)\n",
    "print(f\"Request data shape {input_data.shape}, type {input_data.dtype}\")\n",
    "\n",
    "# Send to the model:\n",
    "result = predictor.predict(input_data)\n",
    "print(f\"Result confidences: {result}\")\n",
    "\n",
    "# Plot the result:\n",
    "plt.figure(figsize=(3, 3))\n",
    "fig = plt.subplot(1, 1, 1)\n",
    "ax = plt.imshow(img, cmap=\"gray\")\n",
    "fig.set_title(f\"Predicted Number {np.argmax(result)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Improvements\n",
    "\n",
    "If you've got the basic train/deploy/call cycle working, congratulations! This core pattern of experimenting in the notebook but executing jobs on scalable hardware is at the heart of the SageMaker data science workflow.\n",
    "\n",
    "There are still plenty of ways we can use the tools better though: Read on for the next challenges!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cut training costs easily with SageMaker Managed Spot Mode\n",
    "\n",
    "AWS Spot Instances let you take advantage of unused capacity in the AWS cloud, at up to a 90% discount versus standard on-demand pricing! For small jobs like this, taking advantage of this discount is as easy as adding a couple of parameters to the Estimator constructor:\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/estimators.html\n",
    "\n",
    "Note that in general, spot capacity is offered at a discounted rate because it's interruptible based on instantaneous demand... Longer-running training jobs should implement checkpoint saving and loading, so that they can efficiently resume if interrupted part way through. More information can be found on the [Managed Spot Training in Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html) page of the [SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parameterize your algorithm\n",
    "\n",
    "Being able to change the parameters of your algorithm at run-time (without modifying the `main.py` script each time) is helpful for making your code more re-usable... But even more so because it's a pre-requisite for automatic hyperparameter tuning!\n",
    "\n",
    "Job parameter parsing should ideally be factored into a separate function, and as a best practice should accept setting values through **both** command line flags (as demonstrated in the [official MXNet MNIST example](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/mxnet_mnist/mnist.py)) **and** the [SageMaker Hyperparameter environment variable(s)](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-container-environmental-variables-user-scripts.html). Perhaps the official MXNet example could be improved by setting environment-variable-driven defaults to the algorithm hyperparameters, the same as it already does for channels?\n",
    "\n",
    "Refactor your job to accept **epochs** and **batch size** as optional parameters, and show how you can set these before each training run through the [Estimator API](https://sagemaker.readthedocs.io/en/stable/estimators.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tune your network hyperparameters\n",
    "\n",
    "Re-use the same approach as before to parameterize some features in the structure of your network: Perhaps the sizes of the `Conv2D` kernels? The number, type, node count, or activation function of layers in the network? No need to stray too far away from the sample architecture!\n",
    "\n",
    "Instead of manually (or programmatically) calling `estimator.fit()` with different hyperparameters each time, we can use SageMaker's Bayesian Hyperparameter Tuning functionality to explore the space more efficiently!\n",
    "\n",
    "The SageMaker SDK Docs give a great [overview](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-automatic-model-tuning) of using the HyperparameterTuner, which you can refer to if you get stuck.\n",
    "\n",
    "First, we'll need to define a specific **metric** to optimize for, which is really a specification of how to scrape metric values from the algorithm's console logs. \n",
    "\n",
    "Next, use the [\\*Parameter](https://sagemaker.readthedocs.io/en/stable/tuner.html) classes (`ContinuousParameter`, `IntegerParameter` and `CategoricalParameter`) to define appropriate ranges for the hyperparameters whose combination you want to optimize.\n",
    "\n",
    "With the original estimator, target metric and parameter ranges defined, you'll be able to create a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/tuner.html) and use that to start a hyperparameter tuning job instead of a single model training job.\n",
    "\n",
    "Pay attention to likely run time and resource consumption when selecting the maximum total number of training jobs and maximum parallel jobs of your hyperparameter tuning run... You can always view and cancel ongoing hyperparameter tuning jobs through the SageMaker Console.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Challenges\n",
    "\n",
    "If you have time, the following challenges are trickier, and might stretch your SageMaker knowledge even further!\n",
    "\n",
    "**Batch Transform / Additional Inference Formats**: As discussed in this notebook, the deployed endpoint expects a particular tensor data format for requests... This complicates the usually-simple task of re-purposing the same model for batch inference (since our data in S3 is in JPEG format). The SageMaker TensorFlow SDK docs provide guidance on accepting custom formats in the [\"Create Python Scripts for Custom Input and Output Formats\"](https://sagemaker.readthedocs.io/en/stable/using_tf.html#create-python-scripts-for-custom-input-and-output-formats) section. If you can refactor your algorithm to accept JPEG requests when deployed as a real-time endpoint, you'll be able to run it as a batch [Transformer](https://sagemaker.readthedocs.io/en/stable/transformer.html) against images in S3 with a simple `estimator.transformer()` call.\n",
    "\n",
    "**Optimized Training Formats**: A dataset like this (containing many tiny objects) may take much less time to load in to the algorithm if we either converted it to the standard Numpy format that Keras distributes it in (just 4 files X_train, Y_train, X_test, Y_test); or *streaming* the data with [SageMaker Pipe Mode](https://aws.amazon.com/blogs/machine-learning/using-pipe-input-mode-for-amazon-sagemaker-algorithms/), instead of downloading it up-front.\n",
    "\n",
    "**Experiment Tracking**: The [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) feature gives a more structured way to track trials across multiple related experiments (for example, different HPO runs, or between HPO and regular model training jobs). You can use the [official SageMaker Experiments Example](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-experiments) for guidance on how to track the experiments in this notebook... and should note that the [SageMaker Experiments SDK Docs](https://sagemaker-experiments.readthedocs.io/en/latest/) are maintained separately, since it's a different Python module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-Up\n",
    "\n",
    "Remember to clean up any persistent resources that aren't needed anymore to save costs: The most significant of these are real-time prediction endpoints, and this SageMaker Notebook Instance.\n",
    "\n",
    "The SageMaker SDK [Predictor](https://sagemaker.readthedocs.io/en/stable/predictors.html) class provides an interface to clean up real-time prediction endpoints; and SageMaker Notebook Instances can be stopped through the SageMaker Console when you're finished.\n",
    "\n",
    "You might also like to clean up any S3 buckets / content we created, to prevent ongoing storage costs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean up any endpoints/etc to release resources\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
